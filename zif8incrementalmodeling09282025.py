# -*- coding: utf-8 -*-
"""ZIF8IncrementalModeling09282025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PADgiQKEl88LORfA7dNwkNPMfeexswQX
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import Callback
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded = files.upload()

# Feature definition

import pandas as pd
import numpy as np
import tensorflow as tf

# Set random seeds for reproducibility
random_seed = 42
np.random.seed(random_seed)
tf.random.set_seed(random_seed)

# Load the data from the Excel file
Dall = pd.read_excel('ZIF8_data.xlsx')

# Solvent amount of mixtures used for fraction calculation
Dall['Total_composition'] = Dall['Zinc'] + Dall['HmIm'] + Dall['Solvent']

# Create molar fraction features
Dall['Zinc_frac'] = Dall['Zinc'] / Dall['Total_composition']
Dall['HmIm_frac'] = Dall['HmIm'] / Dall['Total_composition']
Dall['Solvent_frac'] = Dall['Solvent'] / Dall['Total_composition']

# Insert new fraction features before 'TEM_SEM_Diameter' (output)
# -------------------------------------------------------------
cols = list(Dall.columns)
insert_at = cols.index('TEM_SEM_Diameter')

# Move molar fraction columns for easy analysis
for col in ['Zinc_frac', 'HmIm_frac', 'Solvent_frac']:
    if col in cols:
        cols.remove(col)
cols[insert_at:insert_at] = ['Zinc_frac', 'HmIm_frac', 'Solvent_frac']
Dall = Dall[cols]

# Separate literature and in-house data
# -------------------------------------------------------------
Dall_L = Dall[Dall['Paper_number'] != 0].copy()
Dall_In = Dall[Dall['Paper_number'] == 0].copy()

# Heatmap to compare data
# visualize correlations, which is helpful for seeing nonlinear relationships

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Visualization
# Drop Total_composition before plotting
Dall_p = Dall.drop(columns=['Total_composition'])

# Our data (where Paper_number == 0)
our_data = Dall_p[Dall_p['Paper_number'] == 0].iloc[:, 1:]  # Exclude the first column

# Literature data (where Paper_number != 0)
literature_data = Dall_p[Dall_p['Paper_number'] != 0].iloc[:, 1:]  # Exclude the first column

# All data (no condition on Paper_number)
all_data = Dall_p.iloc[:, 1:]  # Exclude the first column

# Calculate Pearson correlation matrix for each subset
corr_our_data = our_data.corr()  # Pearson correlation for our data
corr_literature_data = literature_data.corr()  # Pearson correlation for literature data
corr_all_data = all_data.corr()  # Pearson correlation for all data

# --- Plot Literature Data Heatmap ---
plt.figure(figsize=(8, 6))
sns.heatmap(corr_literature_data, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)
plt.title("Literature Data Correlation", fontsize=16)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.grid(False)  # Turn off grid
plt.show()

# --- Plot All Data Heatmap ---
plt.figure(figsize=(8, 6))
sns.heatmap(corr_all_data, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)
plt.title("All Data Correlation", fontsize=16)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.grid(False)  # Turn off grid
plt.show()

# --- Heatmap for Selected Variables Only ---
# Define selected variables
selected_vars = [
    'HmIm',
    'Solvent_D',
    'Temperature',
    'Reaction_time',
    'Zinc_frac',
    'TEM_SEM_Diameter'
]

# Subset all_data to selected variables
selected_data = all_data[selected_vars]

# Compute correlation matrix for selected variables
corr_selected = selected_data.corr()

# Plot heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_selected, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)
plt.title("Correlation Heatmap (Selected Variables)", fontsize=16)
plt.xticks(fontsize=12, rotation=45)
plt.yticks(fontsize=12)
plt.grid(False)
plt.tight_layout()
plt.show()

# Save the KDE plotting figure for reporting as the figure is large

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import files  # For download

# --- Preprocessing and Plotting ---
data_combined = Dall.copy()
sns.set(style='white')

data_combined['Data Source'] = data_combined['Paper_number'].apply(lambda x: 'Our Data' if x == 0 else 'Literature')

numeric_cols = data_combined.select_dtypes(include='number').columns.tolist()
selected_cols = [col for col in numeric_cols if col != 'Paper_number']
selected_cols.append('Data Source')
data_for_plot = data_combined[selected_cols]

plot_kws_custom = {
    'alpha': 0.7,
    's': 60,
    'edgecolor': 'k'
}

custom_palette = {
    'Our Data': 'orange',
    'Literature': 'skyblue'
}

# --- Create PairPlot ---
plot2 = sns.pairplot(
    data_for_plot,
    hue='Data Source',
    diag_kind='kde',
    plot_kws=plot_kws_custom,
    palette=custom_palette,
    height=2,
    aspect=1
)
plot2.fig.suptitle("Scatter Matrix (KDE Diagonal)", fontsize=16, y=1.03)

# --- Save the plot ---
save_path = 'scatter_matrix_plot.jpeg'
plot2.fig.savefig(save_path, dpi=300, bbox_inches='tight')

# --- Download the file in Colab ---
files.download(save_path)

# Scatter matrix (pair plots of selected inputs & output)
# Histogram or KDEs on diagonal to show variable distributions.
# Off-diagonal cells visualize scatter plots to indicate trends or clusters.

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Keep 'Paper_number' for hue
data_combined = Dall.copy()

# Use clean background with no grid
sns.set(style='white')

# Label the source of each data point
data_combined['Data Source'] = data_combined['Paper_number'].apply(lambda x: 'Our Data' if x == 0 else 'Literature')

# Attention  --- Define subset of columns to include
selected_vars = [
    'HmIm',
    'Solvent_D',
    'Temperature',
    'Reaction_time',
    'HmIm_frac',
    'TEM_SEM_Diameter',
    'Data Source'  # Keep for coloring
]

# Subset data
data_for_plot = data_combined[selected_vars]

# Customize marker appearance
plot_kws_custom = {
    'alpha': 0.7,
    's': 60,
    'edgecolor': 'k'
}

# Define custom color palette
custom_palette = {
    'Our Data': 'orange',
    'Literature': 'skyblue'
}

# --- Scatter Matrix with KDE on diagonal ---
plot = sns.pairplot(
    data_for_plot,
    hue='Data Source',
    diag_kind='kde',  # Change to 'hist' if you want histograms
    plot_kws=plot_kws_custom,
    palette=custom_palette,
    height=1.5,
    aspect=1
)
plot.fig.suptitle("Scatter Matrix (KDE Diagonal)", fontsize=16, y=1.03)
plt.show()

# Grid-search only, without fine-tuning
# Train an XGBoost model with both <<literature>> && <<in-houst>> data

import xgboost as xgb
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, make_scorer
from scipy.stats.mstats import winsorize

# Using literature data now
# Define input feature columns and output column
input_columns = ['Zinc', 'HmIm', 'Solvent_D', 'Solvent', 'Temperature', 'Reaction_time', 'Zinc_frac', 'HmIm_frac', 'Solvent_frac']
output_column = 'TEM_SEM_Diameter'

# Create input (X) and output (y) variables
X_All = Dall[input_columns].copy()
y_All = Dall[output_column].copy()

# Winsorize y - capping only the top 10% extreme values
y_All_winsor = winsorize(y_All, limits=[0, 0.1])  # adjust limits if needed

# Split data
X_train_All, X_test_All, y_train_All, y_test_All = train_test_split(X_All, y_All_winsor, test_size=0.2, random_state=42)

# Define XGBoost regressor
xgb_model = xgb.XGBRegressor(random_state=42, objective='reg:squarederror')

# Hyperparameter grid
param_grid_xgb = {
    'n_estimators': [50, 100, 150, 200, 250, 300, 350],
    'max_depth': [3, 5, 7, 9, 11, 13, 15],
    'learning_rate': [0.01, 0.1],
    'subsample': [0.2, 0.4, 0.6, 0.8, 1.0]
}

# Grid search setup
grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, scoring=make_scorer(r2_score), cv=5, n_jobs=-1)

# Fit model
grid_search_xgb.fit(X_train_All, y_train_All)

print("XGBoost Best parameters:", grid_search_xgb.best_params_)
best_xgb_All = grid_search_xgb.best_estimator_

# --- save the model
# Save the final model trained with both literature and in-house data, without incrementatl
combined_model_path = "xgb_trained_lit_inhouse_gridsearch.model"
best_xgb_All.get_booster().save_model(combined_model_path)

# Predict and evaluate
y_train_pred_xgb_All = best_xgb_All.predict(X_train_All)
y_test_pred_xgb_All = best_xgb_All.predict(X_test_All)

# Calculate RMSE
train_rmse = np.sqrt(mean_squared_error(y_train_All, y_train_pred_xgb_All))
test_rmse = np.sqrt(mean_squared_error(y_test_All, y_test_pred_xgb_All))

print(f"XGB Train R²: {r2_score(y_train_All, y_train_pred_xgb_All):.3f} | Train RMSE: {train_rmse:.3f}")
print(f"XGB Test R²: {r2_score(y_test_All, y_test_pred_xgb_All):.3f} | Test RMSE: {test_rmse:.3f}")

# Plotting the scatter plots for training and testing predictions
# Attach indices to track back to Dall
train_idx = X_train_All.index
test_idx = X_test_All.index

# Paper_number from original dataset
paper_number_train = Dall.loc[train_idx, 'Paper_number']
paper_number_test = Dall.loc[test_idx, 'Paper_number']

# Build masks
train_lit_mask = (paper_number_train != 0)
train_inhouse_mask = (paper_number_train == 0)
test_lit_mask = (paper_number_test != 0)
test_inhouse_mask = (paper_number_test == 0)

# Plot
plt.figure(figsize=(5, 4))

# Training: literature (blue square)
plt.scatter(
    y_train_All[train_lit_mask],
    y_train_pred_xgb_All[train_lit_mask],
    color='blue', marker='s', s=50, alpha=0.7, label='Train - Literature'
)

# Training: in-house (orange square)
plt.scatter(
    y_train_All[train_inhouse_mask],
    y_train_pred_xgb_All[train_inhouse_mask],
    color='orange', marker='s', s=50, alpha=0.7, label='Train - In-house'
)

# Testing: literature (blue triangle)
plt.scatter(
    y_test_All[test_lit_mask],
    y_test_pred_xgb_All[test_lit_mask],
    color='gray', marker='^', s=80, alpha=0.9, label='Test - Literature'
)

# Testing: in-house (orange triangle)
plt.scatter(
    y_test_All[test_inhouse_mask],
    y_test_pred_xgb_All[test_inhouse_mask],
    color='green', marker='^', s=80, alpha=0.9, label='Test - In-house'
)

# Perfect fit line
min_val = min(y_train_All.min(), y_test_All.min())
max_val = max(y_train_All.max(), y_test_All.max())
plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Perfect Fit')

# Formatting
plt.xlabel('Actual sizes (nm)', fontsize=12)
plt.ylabel('Predicted sizes (nm)', fontsize=12)
plt.legend(frameon=False, fontsize=11)
plt.xticks(fontsize=11)
plt.yticks(fontsize=11)
plt.tight_layout()
plt.show()


# Feature importance plottting
ax = xgb.plot_importance(
    best_xgb_All,
    importance_type='weight',  # This can be also 'gain' or 'cover'
    color='skyblue',              # Change the color of the bars
    height=0.8,
    #max_num_features=50   # only if we like to show partial features
)

# Customizing the title, labels, and ticks
plt.title('Feature Importance', fontsize=12)          # Title font size
plt.xlabel('Scores', fontsize=12)                     # X-axis label font size
plt.ylabel('Features', fontsize=12)                   # Y-axis label font size

# Modify tick font sizes
plt.xticks(fontsize=12)  # X-axis tick font size
plt.yticks(fontsize=12)  # Y-axis tick font size

# Turn off grid
plt.grid(False)

# Show the plot
plt.show()

# Visualziation of the results obtained by using all data together (literature and in-house)
# Combined data are divided into training and testing sets
# Testing set is used for RMSE and R2 evaluation

# Add source labels (in-house vs. literature)
X_test_All_with_source = X_test_All.copy()
X_test_All_with_source['True'] = y_test_All
X_test_All_with_source['Pred'] = y_test_pred_xgb_All
X_test_All_with_source['Error'] = X_test_All_with_source['True'] - X_test_All_with_source['Pred']

# Map source using Dall index
source_lookup = Dall[['Paper_number']]
X_test_All_with_source = X_test_All_with_source.merge(source_lookup, left_index=True, right_index=True)
X_test_All_with_source['Source'] = X_test_All_with_source['Paper_number'].apply(lambda x: 'In-House' if x == 0 else 'Literature')

# Boxplot of Prediction Errors by Source
import seaborn as sns
plt.figure(figsize=(5, 4))
sns.boxplot(data=X_test_All_with_source, x='Source', y='Error', palette='pastel')

plt.axhline(0, color='gray', linestyle='--')
plt.ylabel('Prediction Error (True - Predicted)', fontsize=12)
plt.xlabel('Data Source', fontsize=12)
#plt.title('Prediction Error Distribution by Data Source', fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.grid(False)
plt.tight_layout()
plt.show()

# KDE Plot of Prediction Errors by Source
plt.figure(figsize=(5, 4))
sns.kdeplot(data=X_test_All_with_source[X_test_All_with_source['Source'] == 'In-House']['Error'],
            label='In-House', fill=True, color='skyblue', alpha=0.5)
sns.kdeplot(data=X_test_All_with_source[X_test_All_with_source['Source'] == 'Literature']['Error'],
            label='Literature', fill=True, color='orange', alpha=0.5)

plt.axvline(0, color='gray', linestyle='--')
plt.xlabel('Prediction Error', fontsize=12)
plt.ylabel('Probability', fontsize=12)
#plt.title('KDE of Prediction Errors by Data Source', fontsize=12)
plt.legend(frameon=False, fontsize=12)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
#plt.tight_layout()
plt.show()

# Fine tuning with << in house >> data only

# incremental training (continued training) to improve model performance

# fine-tuning with in-house data only  <<batch-incremental training>> --> full training on dataset A, then continued training on dataset B
# tracking model performance and plotting the results
# showing the scatter plots for comparison

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score, mean_squared_error
from scipy.stats.mstats import winsorize
import matplotlib.pyplot as plt  # make sure plt is imported

# Data prep same as before
Dcopy = Dall.copy()
input_columns = ['Zinc', 'HmIm', 'Solvent_D', 'Solvent', 'Temperature',
                 'Reaction_time', 'Zinc_frac', 'HmIm_frac', 'Solvent_frac']
target_column = 'TEM_SEM_Diameter'

literature_data = Dcopy[Dcopy['Paper_number'] > 0]
inhouse_data = Dcopy[Dcopy['Paper_number'] == 0]

X_lit = literature_data[input_columns]
y_lit = literature_data[target_column]
y_lit_wins = winsorize(y_lit, limits=[0, 0.1])

X_in = inhouse_data[input_columns]
y_in = inhouse_data[target_column]

X_in_finetune, X_in_test, y_in_finetune, y_in_test = train_test_split(
    X_in, y_in, test_size=0.3, random_state=42
)

# Grid search on literature data with sklearn XGBRegressor (to get best params)
'''
param_grid_xgb = {
    'n_estimators': [50, 100],
    'max_depth': [3, 5],
    'learning_rate': [0.01, 0.1],
    'subsample': [0.8, 1.0]
}
'''
param_grid_xgb = {
    'n_estimators': [50, 100, 150, 200, 250, 300, 350],
    'max_depth': [3, 5, 7, 9, 11, 13, 15],
    'learning_rate': [0.01, 0.1],
    'subsample': [0.2, 0.4, 0.6, 0.8, 1.0]
}

xgb_pretrain = xgb.XGBRegressor(random_state=42, objective='reg:squarederror')
grid_pretrain = GridSearchCV(xgb_pretrain, param_grid_xgb, cv=3, scoring='r2', n_jobs=-1)
grid_pretrain.fit(X_lit, y_lit_wins)
best_params = grid_pretrain.best_params_

print("Best params from grid search:", best_params)

# Prepare DMatrix for low-level API
dtrain_lit = xgb.DMatrix(X_lit, label=y_lit_wins)
dtrain_in = xgb.DMatrix(X_in_finetune, label=y_in_finetune)
dtest_in = xgb.DMatrix(X_in_test, label=y_in_test)

# Pretraining with low-level API
params = {
    'objective': 'reg:squarederror',
    'max_depth': best_params['max_depth'],
    'eta': best_params['learning_rate'],  # learning_rate param is eta here
    'subsample': best_params['subsample'],
    'seed': 42
}

num_round_pretrain = best_params['n_estimators']

print("Starting pretraining...")
pretrained_booster = xgb.train(
    params,
    dtrain_lit,
    num_boost_round=num_round_pretrain
)

# --- Save pretrained model
pretrained_model_path = "xgb_pretrained_incremental.model"
pretrained_booster.save_model(pretrained_model_path)

# Incremental fine-tuning starting from pretrained model
num_round_finetune = 50

print("Starting incremental fine-tuning...")
evals_result = {}

finetune_booster = xgb.train(
    params,
    dtrain_in,
    num_boost_round=num_round_finetune,
    xgb_model=pretrained_model_path,
    evals=[(dtrain_in, "train"), (dtest_in, "test")],
    early_stopping_rounds=20,
    evals_result=evals_result,
    verbose_eval=True
)

# --- Save fine-tuned model (in-house data used only)
finetuned_inhouse_model_path = "xgb_finetuned_inhouse.model"
finetune_booster.save_model(finetuned_inhouse_model_path)

# --- Display hyperparameters
print("Final hyperparameters used for fine-tuning:")
print(f"Objective: {params['objective']}")
print(f"Max Depth: {params['max_depth']}")
print(f"Learning Rate (eta): {params['eta']}")
print(f"Subsample: {params['subsample']}")
print(f"Number of Boosting Rounds: {finetune_booster.best_iteration + 1 if hasattr(finetune_booster, 'best_iteration') else num_round_finetune}")

# Plot RMSE trajectory
train_rmse = evals_result['train']['rmse']
test_rmse = evals_result['test']['rmse']

plt.figure(figsize=(8, 4))
plt.plot(train_rmse, label='Train RMSE', color='blue', marker='o', linestyle='-')
plt.plot(test_rmse, label='Test RMSE', color='orange', marker='o', linestyle='-')
plt.xlabel('Boosting Round', fontsize=12)
plt.ylabel('RMSE', fontsize=12)
plt.legend(frameon=False, fontsize=11)
plt.title('Fine-tuning RMSE Trajectory')
plt.legend()
plt.grid(False)
plt.tight_layout()
plt.show()

# --- Load pretrained model ---
pretrained_booster_loaded = xgb.Booster()
pretrained_booster_loaded.load_model(pretrained_model_path)

# --- Predictions ---
y_pred_pretrained = pretrained_booster_loaded.predict(dtest_in)          # pretrained on in-house test
y_pred_test = finetune_booster.predict(dtest_in)                         # fine-tuned on in-house test

d_lit_all = xgb.DMatrix(X_lit)
y_pred_lit_finetuned = finetune_booster.predict(d_lit_all)               # fine-tuned on literature inputs

y_pred_lit_pretrained = pretrained_booster_loaded.predict(d_lit_all)     # pretrained on literature data

# --- Evaluation and plotting function ---
def evaluate_and_plot(y_true, y_pred, title, color, marker, filename):
    r2 = r2_score(y_true, y_pred)
    rmse = mean_squared_error(y_true, y_pred) ** 0.5  # fixed RMSE calc

    plt.figure(figsize=(4, 3))
    plt.scatter(y_true, y_pred, c=color, s=60, alpha=0.7, marker=marker, edgecolors='k')
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)  # perfect fit line

    plt.title(title, fontsize=14)
    plt.xlabel("Actual size (nm)", fontsize=12)
    plt.ylabel("Predicted size (nm)", fontsize=12)
    plt.legend(frameon=False, fontsize=11)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)

    plt.grid(False)
    plt.tight_layout()
    plt.text(0.05, 0.95, f"R² = {r2:.3f}\nRMSE = {rmse:.2f}",
             transform=plt.gca().transAxes, fontsize=11,
             verticalalignment='top', bbox=dict(facecolor='white', alpha=0.6))

    plt.savefig(filename, dpi=300)
    plt.show()

# --- Plot 1: Pretrained model on in-house test data ---
evaluate_and_plot(
    y_true=y_in_test,
    y_pred=y_pred_pretrained,
    title="Pretrained Model vs In-House Test Data",
    color='dodgerblue',
    marker='o',
    filename='plot1_pretrained_vs_inhouse.png'
)

# --- Plot 2: Fine-tuned model on in-house test data ---
evaluate_and_plot(
    y_true=y_in_test,
    y_pred=y_pred_test,
    title="Fine-Tuned Model vs In-House Test Data",
    color='forestgreen',
    marker='^',
    filename='plot2_finetuned_vs_inhouse.png'
)

# --- Plot 3: Fine-tuned model on literature data (winsorized targets) ---
evaluate_and_plot(
    y_true=y_lit_wins,
    y_pred=y_pred_lit_finetuned,
    title="Fine-Tuned Model vs Literature Data (Winsorized)",
    color='darkorange',
    marker='s',
    filename='plot3_finetuned_vs_literature.png'
)

# --- Plot 4: Pretrained model on literature data (winsorized targets) ---
evaluate_and_plot(
    y_true=y_lit_wins,
    y_pred=y_pred_lit_pretrained,
    title="Pretrained Model vs Literature Data (Winsorized)",
    color='purple',
    marker='D',  # diamond marker
    filename='plot4_pretrained_vs_literature.png'
)

# Fine-tuning with "both" << in-house>> and << literature>>  data

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score, mean_squared_error
from scipy.stats.mstats import winsorize
import matplotlib.pyplot as plt

# Data prep same as before
Dcopy = Dall.copy()
input_columns = ['Zinc', 'HmIm', 'Solvent_D', 'Solvent', 'Temperature',
                 'Reaction_time', 'Zinc_frac', 'HmIm_frac', 'Solvent_frac']
target_column = 'TEM_SEM_Diameter'

literature_data = Dcopy[Dcopy['Paper_number'] > 0]
inhouse_data = Dcopy[Dcopy['Paper_number'] == 0]

X_lit = literature_data[input_columns]
y_lit = literature_data[target_column]
y_lit_wins = winsorize(y_lit, limits=[0, 0.1])

X_in = inhouse_data[input_columns]
y_in = inhouse_data[target_column]

X_in_finetune, X_in_test, y_in_finetune, y_in_test = train_test_split(
    X_in, y_in, test_size=0.3, random_state=42
)

# Grid search on literature data with sklearn XGBRegressor (to get best params)
param_grid_xgb = {
    'n_estimators': [50, 100, 150, 200, 250, 300, 350],
    'max_depth': [3, 5, 7, 9, 11, 13, 15],
    'learning_rate': [0.01, 0.1],
    'subsample': [0.2, 0.4, 0.6, 0.8, 1.0]
}

xgb_pretrain = xgb.XGBRegressor(random_state=42, objective='reg:squarederror')
grid_pretrain = GridSearchCV(xgb_pretrain, param_grid_xgb, cv=3, scoring='r2', n_jobs=-1)
grid_pretrain.fit(X_lit, y_lit_wins)
best_params = grid_pretrain.best_params_

print("Best params from grid search:", best_params)

# Prepare DMatrix for low-level API
dtrain_lit = xgb.DMatrix(X_lit, label=y_lit_wins)
dtrain_in = xgb.DMatrix(X_in_finetune, label=y_in_finetune)
dtest_in = xgb.DMatrix(X_in_test, label=y_in_test)

# Pretraining with low-level API
params = {
    'objective': 'reg:squarederror',
    'max_depth': best_params['max_depth'],
    'eta': best_params['learning_rate'],  # learning_rate param is eta here
    'subsample': best_params['subsample'],
    'seed': 42
}

num_round_pretrain = best_params['n_estimators']

print("Starting pretraining...")
pretrained_booster = xgb.train(
    params,
    dtrain_lit,
    num_boost_round=num_round_pretrain
)

# --- Save pretrained model
# --- pretrained model will be identical as no change in data and model setup
pretrained_model_path = "xgb_pretrained_incremental.model"
pretrained_booster.save_model(pretrained_model_path)

# Combine literature + in-house fine-tune data for incremental training
X_combined = pd.concat([X_lit, X_in_finetune], axis=0)
y_combined = pd.concat([pd.Series(y_lit_wins, index=X_lit.index), y_in_finetune], axis=0)

dtrain_combined = xgb.DMatrix(X_combined, label=y_combined)

num_round_finetune = 50

print("Starting incremental fine-tuning on combined data...")
evals_result = {}

booster_finetuned_combined = xgb.train(
    params,
    dtrain_combined,
    num_boost_round=num_round_finetune,
    xgb_model=pretrained_model_path,
    evals=[(dtrain_combined, "train"), (dtest_in, "test")],
    early_stopping_rounds=20,
    evals_result=evals_result,
    verbose_eval=True
)

# --- Save with a differet name for comparions later
# --- make sure all models saved with differnet names
finetuned_combined_model_path = "xgb_finetuned_combined.model"
booster_finetuned_combined.save_model(finetuned_combined_model_path)

# Plot RMSE trajectory
train_rmse = evals_result['train']['rmse']
test_rmse = evals_result['test']['rmse']

plt.figure(figsize=(8, 4))
plt.plot(train_rmse, label='Train RMSE', color='blue', marker='o', linestyle='-')
plt.plot(test_rmse, label='Test RMSE', color='orange', marker='o', linestyle='-')
plt.xlabel('Boosting Round', fontsize=12)
plt.ylabel('RMSE', fontsize=12)
plt.legend(frameon=False, fontsize=11)
plt.title('Fine-tuning RMSE Trajectory (Combined Dataset)')
plt.legend()
plt.grid(False)
plt.tight_layout()
plt.show()

# --- Load pretrained model ---
pretrained_booster_loaded = xgb.Booster()
pretrained_booster_loaded.load_model(pretrained_model_path)

# --- Predictions ---
y_pred_pretrained = pretrained_booster_loaded.predict(dtest_in)          # pretrained on in-house test
y_pred_test = booster_finetuned_combined.predict(dtest_in)                         # fine-tuned on in-house test

d_lit_all = xgb.DMatrix(X_lit)
y_pred_lit_finetuned = booster_finetuned_combined.predict(d_lit_all)               # fine-tuned on literature inputs

y_pred_lit_pretrained = pretrained_booster_loaded.predict(d_lit_all)     # pretrained on literature data

# --- Evaluation and plotting function (same as before) ---
def evaluate_and_plot(y_true, y_pred, title, color, marker, filename):
    r2 = r2_score(y_true, y_pred)
    rmse = mean_squared_error(y_true, y_pred) ** 0.5

    plt.figure(figsize=(4, 3))
    plt.scatter(y_true, y_pred, c=color, s=60, alpha=0.7, marker=marker, edgecolors='k')
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)

    plt.title(title, fontsize=14)
    plt.xlabel("Actual size (nm)", fontsize=12)
    plt.ylabel("Predicted size (nm)", fontsize=12)
    plt.legend(frameon=False, fontsize=11)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)

    plt.grid(False)
    plt.tight_layout()
    plt.text(0.05, 0.95, f"R² = {r2:.3f}\nRMSE = {rmse:.2f}",
             transform=plt.gca().transAxes, fontsize=11,
             verticalalignment='top', bbox=dict(facecolor='white', alpha=0.6))

    plt.savefig(filename, dpi=300)
    plt.show()

# --- Plot 1: Pretrained model on in-house test data ---
evaluate_and_plot(
    y_true=y_in_test,
    y_pred=y_pred_pretrained,
    title="Pretrained Model vs In-House Test Data",
    color='dodgerblue',
    marker='o',
    filename='plot1_pretrained_vs_inhouse.png'
)

# --- Plot 2: Fine-tuned model on in-house test data ---
evaluate_and_plot(
    y_true=y_in_test,
    y_pred=y_pred_test,
    title="Fine-Tuned Model vs In-House Test Data",
    color='forestgreen',
    marker='^',
    filename='plot2_finetuned_vs_inhouse.png'
)

# --- Plot 3: Fine-tuned model on literature data (winsorized targets) ---
evaluate_and_plot(
    y_true=y_lit_wins,
    y_pred=y_pred_lit_finetuned,
    title="Fine-Tuned Model vs Literature Data (Winsorized)",
    color='darkorange',
    marker='s',
    filename='plot3_finetuned_vs_literature.png'
)

# --- Plot 4: Pretrained model on literature data (winsorized targets) ---
evaluate_and_plot(
    y_true=y_lit_wins,
    y_pred=y_pred_lit_pretrained,
    title="Pretrained Model vs Literature Data (Winsorized)",
    color='purple',
    marker='D',
    filename='plot4_pretrained_vs_literature.png'
)

# Testing the effect of data augmentation on model performance
# Split data first and only augment training portion of in-house data

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score, mean_squared_error
from scipy.stats.mstats import winsorize
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import euclidean_distances
import random

# --- Synthetic data augmentation function ---
def generate_synthetic_data(X, Y):
    distances = euclidean_distances(X)
    flattened_distances = distances[np.triu_indices_from(distances, k=1)]
    threshold = np.percentile(flattened_distances, 5)
    print(f"Adaptive threshold (5th percentile distance): {threshold}")

    synthetic_data = []
    for i in range(len(X)):
        for j in range(i + 1, len(X)):
            dist = distances[i, j]
            if dist < threshold:
                alpha = random.random()
                X_synthetic = alpha * X.iloc[i] + (1 - alpha) * X.iloc[j]
                Y_synthetic = alpha * Y.iloc[i] + (1 - alpha) * Y.iloc[j]
                synthetic_data.append(np.concatenate(([Y_synthetic], X_synthetic)))
    return np.array(synthetic_data)

# Data prep same as before
Dcopy = Dall.copy()
input_columns = ['Zinc', 'HmIm', 'Solvent_D', 'Solvent', 'Temperature',
                 'Reaction_time', 'Zinc_frac', 'HmIm_frac', 'Solvent_frac']
target_column = 'TEM_SEM_Diameter'

literature_data = Dcopy[Dcopy['Paper_number'] > 0]
inhouse_data = Dcopy[Dcopy['Paper_number'] == 0]

X_lit = literature_data[input_columns]
y_lit = literature_data[target_column]
y_lit_wins = winsorize(y_lit, limits=[0, 0.1])

X_in = inhouse_data[input_columns]
y_in = inhouse_data[target_column]

# === Step 1: Split in-house data FIRST ===
X_in_train, X_in_test, y_in_train, y_in_test = train_test_split(
    X_in, y_in, test_size=0.3, random_state=42
)

# === Step 2: Generate synthetic data ONLY on in-house TRAINING data ===
print("Generating synthetic data for in-house training set...")
synthetic_array = generate_synthetic_data(X_in_train.reset_index(drop=True), y_in_train.reset_index(drop=True))

if synthetic_array.size == 0:
    print("No synthetic samples generated. Proceeding without augmentation.")
    X_in_train_aug = X_in_train
    y_in_train_aug = y_in_train
else:
    y_synthetic = synthetic_array[:, 0]
    X_synthetic = synthetic_array[:, 1:]
    X_in_train_aug = pd.concat([X_in_train.reset_index(drop=True), pd.DataFrame(X_synthetic, columns=input_columns)], ignore_index=True)
    y_in_train_aug = pd.concat([y_in_train.reset_index(drop=True), pd.Series(y_synthetic)], ignore_index=True)
    print(f"Synthetic samples added to training set: {len(y_synthetic)}")

# === Grid search on literature data with sklearn XGBRegressor (to get best params) ===
param_grid_xgb = {
    'n_estimators': [50, 100, 150, 200, 250, 300, 350],
    'max_depth': [3, 5, 7, 9, 11, 13, 15],
    'learning_rate': [0.01, 0.1],
    'subsample': [0.2, 0.4, 0.6, 0.8, 1.0]
}

xgb_pretrain = xgb.XGBRegressor(random_state=42, objective='reg:squarederror')
grid_pretrain = GridSearchCV(xgb_pretrain, param_grid_xgb, cv=3, scoring='r2', n_jobs=-1)
grid_pretrain.fit(X_lit, y_lit_wins)
best_params = grid_pretrain.best_params_

print("Best params from grid search:", best_params)

# Prepare DMatrix for low-level API
dtrain_lit = xgb.DMatrix(X_lit, label=y_lit_wins)
dtest_in = xgb.DMatrix(X_in_test, label=y_in_test)

# Pretraining with low-level API
params = {
    'objective': 'reg:squarederror',
    'max_depth': best_params['max_depth'],
    'eta': best_params['learning_rate'],
    'subsample': best_params['subsample'],
    'seed': 42
}

num_round_pretrain = best_params['n_estimators']

print("Starting pretraining...")
pretrained_booster = xgb.train(
    params,
    dtrain_lit,
    num_boost_round=num_round_pretrain
)

pretrained_model_path = "xgb_pretrained_incremental.model"
pretrained_booster.save_model(pretrained_model_path)

# === Combine literature and augmented in-house TRAINING data for fine-tuning ===
X_combined = pd.concat([X_lit, X_in_train_aug], axis=0)
y_combined = pd.concat([pd.Series(y_lit_wins, index=X_lit.index), y_in_train_aug], axis=0)

dtrain_combined = xgb.DMatrix(X_combined, label=y_combined)

num_round_finetune = 50

print("Starting incremental fine-tuning on combined data (with augmented in-house training)...")
evals_result = {}

booster_finetuned_combined_augmented = xgb.train(
    params,
    dtrain_combined,
    num_boost_round=num_round_finetune,
    xgb_model=pretrained_model_path,
    evals=[(dtrain_combined, "train"), (dtest_in, "test")],
    early_stopping_rounds=20,
    evals_result=evals_result,
    verbose_eval=True
)

# --- Save the final model
finetuned_augmented_model_path = "xgb_finetuned_combined_augmented.model"
booster_finetuned_combined_augmented.save_model(finetuned_augmented_model_path)

# Plot RMSE trajectory
train_rmse = evals_result['train']['rmse']
test_rmse = evals_result['test']['rmse']

plt.figure(figsize=(8, 4))
plt.plot(train_rmse, label='Train RMSE', color='blue', marker='o', linestyle='-')
plt.plot(test_rmse, label='Test RMSE', color='orange', marker='o', linestyle='-')
plt.xlabel('Boosting Round', fontsize=12)
plt.ylabel('RMSE', fontsize=12)
plt.title('Fine-tuning RMSE Trajectory (Combined Dataset with Augmented In-house Training)')
plt.legend()
plt.grid(False)
plt.tight_layout()
plt.show()

# Load pretrained model
pretrained_booster_loaded = xgb.Booster()
pretrained_booster_loaded.load_model(pretrained_model_path)

# Predictions
y_pred_pretrained = pretrained_booster_loaded.predict(dtest_in)
y_pred_test = booster_finetuned_combined_augmented.predict(dtest_in)

d_lit_all = xgb.DMatrix(X_lit)
y_pred_lit_finetuned = booster_finetuned_combined_augmented.predict(d_lit_all)
y_pred_lit_pretrained = pretrained_booster_loaded.predict(d_lit_all)

# Evaluation and plotting function -- make sure presentation is the same.
evaluate_and_plot(
    y_true=y_in_test,
    y_pred=y_pred_pretrained,
    title="Pretrained Model vs In-House Test Data",
    color='dodgerblue',
    marker='o',
    filename='plot1_pretrained_vs_inhouse.png'
)

evaluate_and_plot(
    y_true=y_in_test,
    y_pred=y_pred_test,
    title="Fine-Tuned Model vs In-House Test Data (Augmented)",
    color='forestgreen',
    marker='^',
    filename='plot2_finetuned_vs_inhouse_augmented.png'
)

evaluate_and_plot(
    y_true=y_lit_wins,
    y_pred=y_pred_lit_finetuned,
    title="Fine-Tuned Model vs Literature Data (Winsorized)",
    color='darkorange',
    marker='s',
    filename='plot3_finetuned_vs_literature_augmented.png'
)

evaluate_and_plot(
    y_true=y_lit_wins,
    y_pred=y_pred_lit_pretrained,
    title="Pretrained Model vs Literature Data (Winsorized)",
    color='purple',
    marker='D',
    filename='plot4_pretrained_vs_literature.png'
)

# Testing the effect of data augmentation on model performance
# Model fine-tuned with 'both' literature and in-house data (including the synthetic data)
# Augmented in-house data unseen to model and saved for testing

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score, mean_squared_error
from scipy.stats.mstats import winsorize
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import euclidean_distances
import random

# --- Synthetic data augmentation function ---
def generate_synthetic_data(X, Y):
    distances = euclidean_distances(X)
    flattened_distances = distances[np.triu_indices_from(distances, k=1)]
    threshold = np.percentile(flattened_distances, 5)
    print(f"Adaptive threshold (5th percentile distance): {threshold}")

    synthetic_data = []
    for i in range(len(X)):
        for j in range(i + 1, len(X)):
            dist = distances[i, j]
            if dist < threshold:
                alpha = random.random()
                X_synthetic = alpha * X.iloc[i] + (1 - alpha) * X.iloc[j]
                Y_synthetic = alpha * Y.iloc[i] + (1 - alpha) * Y.iloc[j]
                synthetic_data.append(np.concatenate(([Y_synthetic], X_synthetic)))
    return np.array(synthetic_data)

# Data prep same as before
Dcopy = Dall.copy()
input_columns = ['Zinc', 'HmIm', 'Solvent_D', 'Solvent', 'Temperature',
                 'Reaction_time', 'Zinc_frac', 'HmIm_frac', 'Solvent_frac']
target_column = 'TEM_SEM_Diameter'

literature_data = Dcopy[Dcopy['Paper_number'] > 0]
inhouse_data = Dcopy[Dcopy['Paper_number'] == 0]

X_lit = literature_data[input_columns]
y_lit = literature_data[target_column]
y_lit_wins = winsorize(y_lit, limits=[0, 0.1])

X_in = inhouse_data[input_columns]
y_in = inhouse_data[target_column]

# === Generate synthetic data for the entire in-house dataset ===
print("Generating synthetic in-house data...")
synthetic_array = generate_synthetic_data(X_in.reset_index(drop=True), y_in.reset_index(drop=True))

if synthetic_array.size == 0:
    print("No synthetic samples generated. Proceeding without augmentation.")
    X_in_aug = X_in
    y_in_aug = y_in
else:
    # Convert synthetic data array to DataFrame and Series
    y_synthetic = synthetic_array[:, 0]
    X_synthetic = synthetic_array[:, 1:]
    X_in_aug = pd.concat([X_in.reset_index(drop=True), pd.DataFrame(X_synthetic, columns=input_columns)], ignore_index=True)
    y_in_aug = pd.concat([y_in.reset_index(drop=True), pd.Series(y_synthetic)], ignore_index=True)
    print(f"Synthetic samples added: {len(y_synthetic)}")

# === Split the augmented in-house data into training and testing sets ===
X_in_finetune, X_in_test, y_in_finetune, y_in_test = train_test_split(
    X_in_aug, y_in_aug, test_size=0.3, random_state=42
)

# Grid search on literature data with sklearn XGBRegressor (to get best params)
param_grid_xgb = {
    'n_estimators': [50, 100, 150, 200, 250, 300, 350],
    'max_depth': [3, 5, 7, 9, 11, 13, 15],
    'learning_rate': [0.01, 0.1],
    'subsample': [0.2, 0.4, 0.6, 0.8, 1.0]
}

xgb_pretrain = xgb.XGBRegressor(random_state=42, objective='reg:squarederror')
grid_pretrain = GridSearchCV(xgb_pretrain, param_grid_xgb, cv=3, scoring='r2', n_jobs=-1)
grid_pretrain.fit(X_lit, y_lit_wins)
best_params = grid_pretrain.best_params_

print("Best params from grid search:", best_params)

# Prepare DMatrix for low-level API
dtrain_lit = xgb.DMatrix(X_lit, label=y_lit_wins)
dtest_in = xgb.DMatrix(X_in_test, label=y_in_test)

# Pretraining with low-level API
params = {
    'objective': 'reg:squarederror',
    'max_depth': best_params['max_depth'],
    'eta': best_params['learning_rate'],
    'subsample': best_params['subsample'],
    'seed': 42
}

num_round_pretrain = best_params['n_estimators']

print("Starting pretraining...")
pretrained_booster = xgb.train(
    params,
    dtrain_lit,
    num_boost_round=num_round_pretrain
)

pretrained_model_path = "xgb_pretrained_incremental.model"
pretrained_booster.save_model(pretrained_model_path)

# === Combine literature and augmented in-house fine-tune data ===
X_combined = pd.concat([X_lit, X_in_finetune], axis=0)
y_combined = pd.concat([pd.Series(y_lit_wins, index=X_lit.index), y_in_finetune], axis=0)

dtrain_combined = xgb.DMatrix(X_combined, label=y_combined)

num_round_finetune = 50

print("Starting incremental fine-tuning on combined data (with augmentation)...")
evals_result = {}

booster_finetuned_combined_augmented = xgb.train(
    params,
    dtrain_combined,
    num_boost_round=num_round_finetune,
    xgb_model=pretrained_model_path,
    evals=[(dtrain_combined, "train"), (dtest_in, "test")],
    early_stopping_rounds=20,
    evals_result=evals_result,
    verbose_eval=True
)

# --- save the final model
finetuned_augmented_model_path = "xgb_finetuned_combined_augmented.model"
booster_finetuned_combined_augmented.save_model(finetuned_augmented_model_path)

# Plot RMSE trajectory
train_rmse = evals_result['train']['rmse']
test_rmse = evals_result['test']['rmse']

plt.figure(figsize=(8, 4))
plt.plot(train_rmse, label='Train RMSE', color='blue', marker='o', linestyle='-')
plt.plot(test_rmse, label='Test RMSE', color='orange', marker='o', linestyle='-')
plt.xlabel('Boosting Round', fontsize=12)
plt.ylabel('RMSE', fontsize=12)
ax2.legend(frameon=False, fontsize=10)
plt.title('Fine-tuning RMSE Trajectory (Combined Dataset with Augmented In-house)')
plt.legend()
plt.grid(False)
plt.tight_layout()
plt.show()

# Load pretrained model
pretrained_booster_loaded = xgb.Booster()
pretrained_booster_loaded.load_model(pretrained_model_path)

# Predictions
y_pred_pretrained = pretrained_booster_loaded.predict(dtest_in)
y_pred_test = booster_finetuned_combined_augmented.predict(dtest_in)

d_lit_all = xgb.DMatrix(X_lit)
y_pred_lit_finetuned = booster_finetuned_combined_augmented.predict(d_lit_all)
y_pred_lit_pretrained = pretrained_booster_loaded.predict(d_lit_all)

# Evaluation and plotting function -- make sure presentation is the same.

evaluate_and_plot(
    y_true=y_in_test,
    y_pred=y_pred_pretrained,
    title="Pretrained Model vs In-House Test Data",
    color='dodgerblue',
    marker='o',
    filename='plot1_pretrained_vs_inhouse.png'
)

evaluate_and_plot(
    y_true=y_in_test,
    y_pred=y_pred_test,
    title="Fine-Tuned Model vs In-House Test Data (Augmented)",
    color='forestgreen',
    marker='^',
    filename='plot2_finetuned_vs_inhouse_augmented.png'
)

evaluate_and_plot(
    y_true=y_lit_wins,
    y_pred=y_pred_lit_finetuned,
    title="Fine-Tuned Model vs Literature Data (Winsorized)",
    color='darkorange',
    marker='s',
    filename='plot3_finetuned_vs_literature_augmented.png'
)

evaluate_and_plot(
    y_true=y_lit_wins,
    y_pred=y_pred_lit_pretrained,
    title="Pretrained Model vs Literature Data (Winsorized)",
    color='purple',
    marker='D',
    filename='plot4_pretrained_vs_literature.png'
)

# Model structure comparison

import xgboost as xgb
import matplotlib.pyplot as plt
import pandas as pd

# --- Function to summarize tree structure
def summarize_model_trees(model, model_name=""):
    # Check if it's a Booster object or XGBRegressor
    if isinstance(model, xgb.Booster):
        booster = model
    else:
        booster = model.get_booster()

    df = booster.trees_to_dataframe()

    n_trees = df['Tree'].nunique()
    total_splits = df[df['Feature'] != 'Leaf'].shape[0]
    total_leaves = df[df['Feature'] == 'Leaf'].shape[0]

    avg_splits_per_tree = total_splits / n_trees
    avg_leaves_per_tree = total_leaves / n_trees

    summary = {
        'Model': model_name,
        'Total Splits': total_splits,
        'Total Leaves': total_leaves,
        'Avg Splits/Tree': round(avg_splits_per_tree, 2),
        'Avg Leaves/Tree': round(avg_leaves_per_tree, 2)
    }

    return pd.DataFrame([summary])


# --- Paths to saved models
lit_inhouse_model_path = "xgb_trained_lit_inhouse_gridsearch.model"
pretrained_model_path = "xgb_pretrained_incremental.model"
finetuned_inhouse_model_path = "xgb_finetuned_inhouse.model"
finetuned_combined_model_path = "xgb_finetuned_combined.model"
finetuned_augmented_model_path = "xgb_finetuned_combined_augmented.model"

# --- Reload all models from disk
booster_lit_inhouse = xgb.Booster()
booster_lit_inhouse.load_model(lit_inhouse_model_path)

pretrained_booster_loaded = xgb.Booster()
pretrained_booster_loaded.load_model(pretrained_model_path)

finetuned_inhouse_booster_loaded = xgb.Booster()
finetuned_inhouse_booster_loaded.load_model(finetuned_inhouse_model_path)

finetuned_combined_booster_loaded = xgb.Booster()
finetuned_combined_booster_loaded.load_model(finetuned_combined_model_path)

finetuned_augmented_booster_loaded = xgb.Booster()
finetuned_augmented_booster_loaded.load_model(finetuned_augmented_model_path)

# --- Summarize all reloaded models
summary_lit_inhouse = summarize_model_trees(booster_lit_inhouse, "Baseline")
summary_pretrained = summarize_model_trees(pretrained_booster_loaded, "Pre-trained (Literature)")
summary_finetuned_inhouse = summarize_model_trees(finetuned_inhouse_booster_loaded, "Fine-tuned (In-House)")
summary_finetuned_combined = summarize_model_trees(finetuned_combined_booster_loaded, "Fine-tuned (Combined)")
summary_finetuned_combined_augmented = summarize_model_trees(finetuned_augmented_booster_loaded, "Fine-tuned (Combined + Augmented)")

# --- Combine all summaries into a single table
summary_all = pd.concat([
    summary_lit_inhouse,
    summary_pretrained,
    summary_finetuned_inhouse,
    summary_finetuned_combined,
    summary_finetuned_combined_augmented
], ignore_index=True)

# --- Display or export summary
print(summary_all)
# Optionally: summary_all.to_csv("model_structure_summary.csv", index=False)

# --- Plotting Section ---
summary_df = summary_all.set_index("Model")

# Plot 1: Total Splits and Leaves
fig1, ax1 = plt.subplots(figsize=(10, 5))
summary_df[['Total Splits', 'Total Leaves']].plot(
    kind='bar',
    ax=ax1,
    color=['lightcoral', 'gold'],
    width=0.7,
    edgecolor='black'
)
ax1.set_ylabel('Total Count', fontsize=12)
ax1.set_title('Total Splits and Leaves per Model', fontsize=14)
ax1.set_xticklabels(summary_df.index, rotation=15, fontsize=11)
ax1.tick_params(axis='y', labelsize=10)
ax1.legend(frameon=False, fontsize=10)
plt.tight_layout()
plt.show()

# Plot 2: Average Splits and Leaves per Tree
fig2, ax2 = plt.subplots(figsize=(10, 5))
summary_df[['Avg Splits/Tree', 'Avg Leaves/Tree']].plot(
    kind='bar',
    ax=ax2,
    color=['mediumpurple', 'mediumseagreen'],
    width=0.7,
    edgecolor='black'
)
ax2.set_ylabel('Average per Tree', fontsize=12)
ax2.set_title('Average Splits and Leaves per Tree', fontsize=14)
ax2.set_xticklabels(summary_df.index, rotation=15, fontsize=11)
ax2.tick_params(axis='y', labelsize=10)
ax2.legend(frameon=False, fontsize=10)
plt.tight_layout()
plt.show()

# SHAP value combined with PCA for analysis

import pandas as pd
import shap
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA    # 2D plotting
from mpl_toolkits.mplot3d import Axes3D  # 3D plotting
from sklearn.cluster import KMeans
import xgboost as xgb
import os

# --- Configuration
input_columns = ['Zinc', 'HmIm', 'Solvent_D', 'Solvent', 'Temperature', 'Reaction_time',
                 'Zinc_frac', 'HmIm_frac', 'Solvent_frac']
output_column = 'TEM_SEM_Diameter'
model_filename = "xgb_finetuned_combined_augmented.model"

# --- Check if model created
if not os.path.exists(model_filename):
    raise FileNotFoundError(f"Model file '{model_filename}' not found in current session.")

# --- Make a copy to preserve original data
Dall_cluster_copy = Dall.copy()

# --- Load the Booster model
finetuned_augmented_booster_loaded = xgb.Booster()
finetuned_augmented_booster_loaded.load_model(model_filename)
print("Model loaded successfully.")

# --- Create DMatrix for prediction with feature names
dtest = xgb.DMatrix(Dall_cluster_copy[input_columns].values, feature_names=input_columns)

# --- Predict using the Booster
Dall_cluster_copy['Predicted_Size'] = finetuned_augmented_booster_loaded.predict(dtest)

# --- Winsorize Predicted_Size by capping top 10% values (limits=[0, 0.1])
Dall_cluster_copy['Predicted_Size_Winsor'] = winsorize(Dall_cluster_copy['Predicted_Size'], limits=[0, 0.1])

# --- Compute SHAP values using TreeExplainer
explainer = shap.TreeExplainer(finetuned_augmented_booster_loaded)
shap_values = explainer.shap_values(dtest)  # shape: (n_samples, n_features)

# --- Cluster SHAP vectors
n_clusters = 3  # adjustable
kmeans = KMeans(n_clusters=n_clusters, random_state=0)
Dall_cluster_copy['SHAP_Cluster'] = kmeans.fit_predict(shap_values)

# ======== Add Data Source info to visualize clusters ========
# Add source column: 'In-house' if Paper_number == 0 else 'Literature'
Dall_cluster_copy['Data_Source'] = Dall_cluster_copy['Paper_number'].apply(
    lambda x: 'In-house' if x == 0 else 'Literature'
)

# Print counts of samples per cluster and source
print("\nCluster vs Data Source Counts:")
print(pd.crosstab(Dall_cluster_copy['SHAP_Cluster'], Dall_cluster_copy['Data_Source']))

# Print proportions per cluster
print("\nCluster vs Data Source Proportions:")
print(pd.crosstab(Dall_cluster_copy['SHAP_Cluster'], Dall_cluster_copy['Data_Source'], normalize='index').round(2))

# Additional plot distribution as stacked bar chart
cluster_source_counts = pd.crosstab(Dall_cluster_copy['SHAP_Cluster'], Dall_cluster_copy['Data_Source'])
cluster_source_counts.plot(kind='bar', stacked=True, figsize=(4.2,3), colormap='tab20')
plt.ylabel('Number of Samples')
plt.title('Distribution of Data Source within SHAP Clusters')
plt.legend(frameon=False)
plt.show()

# --- PCA for 2D visualization of SHAP explanations
pca = PCA(n_components=2)
shap_pca = pca.fit_transform(shap_values)

plt.figure(figsize=(4, 3))
for c in range(n_clusters):
    plt.scatter(shap_pca[Dall_cluster_copy['SHAP_Cluster'] == c, 0],
                shap_pca[Dall_cluster_copy['SHAP_Cluster'] == c, 1],
                label=f'Cluster {c}')
plt.title("Clustering of SHAP Explanation Vectors (ZIF-8 Synthesis)")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.legend(frameon=False)
plt.grid(False)
# plt.tight_layout()
plt.show()

# --- PCA for 3D visualization of SHAP explanations
pca_3d = PCA(n_components=3)
shap_pca_3d = pca_3d.fit_transform(shap_values)

fig = plt.figure(figsize=(5, 4))
ax = fig.add_subplot(111, projection='3d')

for c in range(n_clusters):
    ax.scatter(
        shap_pca_3d[Dall_cluster_copy['SHAP_Cluster'] == c, 0],
        shap_pca_3d[Dall_cluster_copy['SHAP_Cluster'] == c, 1],
        shap_pca_3d[Dall_cluster_copy['SHAP_Cluster'] == c, 2],
        label=f'Cluster {c}',
        s=40
    )

ax.set_title("3D Clustering of SHAP Explanation Vectors (ZIF-8 Synthesis)")
ax.set_xlabel("PCA 1")
ax.set_ylabel("PCA 2")
ax.set_zlabel("PCA 3")
ax.grid(False)  # turn off the grid
# Place legend inside the plot, top right corner
ax.legend(frameon=False, loc='upper left', bbox_to_anchor=(0.01, 0.9))
plt.show()

# --- Print cluster-wise summary of synthesis parameters and winsorized predictions
print("\n--- Cluster Summary (Mean Values with Winsorized Predicted Size) ---")
cluster_summary = Dall_cluster_copy.groupby('SHAP_Cluster')[input_columns + ['Predicted_Size_Winsor']].mean()
print(cluster_summary.round(2))

# --- Save clustered dataset to Excel
# output_filename = "ZIF8_SHAP_Clustered_Copy_Booster_Winsor.xlsx"
# Dall_cluster_copy.to_excel(output_filename, index=False)
# print(f"Clustered data saved to: {output_filename}")

# --- SHAP Beeswarm plot: shows the distribution of SHAP values across samples
shap.summary_plot(shap_values, features=Dall_cluster_copy[input_columns],
                  feature_names=input_columns, plot_type="violin")

# Broken y-axis for cluster-wise Mean SHAP Values Bar Plot

import numpy as np
import matplotlib.pyplot as plt

# Calculate mean absolute SHAP values per cluster and feature
mean_abs_shap = pd.DataFrame(np.abs(shap_values), columns=input_columns)
mean_abs_shap['Cluster'] = Dall_cluster_copy['SHAP_Cluster']
cluster_shap_means = mean_abs_shap.groupby('Cluster').mean()

# Prepare data for plotting
features = cluster_shap_means.columns
clusters = cluster_shap_means.index
bar_width = 0.25
x = np.arange(len(features))

fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10, 5), gridspec_kw={'height_ratios': [1, 3]})

# Upper plot: zoomed on the large values
ax1.bar(x - bar_width, cluster_shap_means.loc[0], width=bar_width, label='Cluster 0')
ax1.bar(x, cluster_shap_means.loc[1], width=bar_width, label='Cluster 1')
ax1.bar(x + bar_width, cluster_shap_means.loc[2], width=bar_width, label='Cluster 2')

ax1.set_ylim(120, cluster_shap_means.values.max() + 20)  # zoom in on large values
ax1.spines['bottom'].set_visible(False)
ax1.tick_params(axis='x', which='both', bottom=False, labelbottom=False)  # hide x axis labels on upper plot

# Lower plot: zoomed on the smaller values
ax2.bar(x - bar_width, cluster_shap_means.loc[0], width=bar_width)
ax2.bar(x, cluster_shap_means.loc[1], width=bar_width)
ax2.bar(x + bar_width, cluster_shap_means.loc[2], width=bar_width)

ax2.set_ylim(0, 120)  # zoom in on small values
ax2.spines['top'].set_visible(False)

# Draw diagonal lines to indicate the break
d = .015  # size of diagonal lines in axes coordinates
kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False)
ax1.plot((-d, +d), (-d, +d), **kwargs)        # top-left diagonal
ax1.plot((1 - d, 1 + d), (-d, +d), **kwargs)  # top-right diagonal

kwargs.update(transform=ax2.transAxes)  # switch to the bottom axes
ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)  # bottom-left diagonal
ax2.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)  # bottom-right diagonal

# X-axis labels
ax2.set_xticks(x)
ax2.set_xticklabels(features, rotation=45, ha='right')

# Labels and legend
ax2.set_ylabel('Mean |SHAP value|')
fig.suptitle('Mean Absolute SHAP Values per Feature by Cluster with Broken Y-Axis')
# ax1.legend(title='Cluster', frameon=False)
ax1.legend(title=None, loc='upper right', bbox_to_anchor=(1, 1.1), frameon=False)

plt.tight_layout()
plt.show()